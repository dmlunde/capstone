{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Eminem RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSP1Iwr8XgZz",
        "colab_type": "text"
      },
      "source": [
        "# Eminem RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqsypHKRnLAJ",
        "colab_type": "code",
        "outputId": "f55983e7-3bbb-4c28-d5a1-2ade7b31a10f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QscQo_h96Nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import sys\n",
        "import numpy as np\n",
        "import string\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.text import Tokenizer, one_hot, hashing_trick\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator, pad_sequences\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "from random import randint\n",
        "from pickle import load, dump\n",
        "\n",
        "import io\n",
        "import pandas as pd\n",
        "import time\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NnOqni0OrtF",
        "colab_type": "code",
        "outputId": "517d6362-6d35-490f-e525-8941cc66d974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "lyrics_by_song_with_headers = pd.read_csv('/content/drive/My Drive/Eminem Lyrics with Headers', index_col=0)\n",
        "lyrics_by_song_with_headers.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Any rapper saying those kind of rhymes In this day and age in this period of time Tryna battle Eminem is worse than David Starr tryna battle Proof, Eye-Ku, BFlat and Bizarre (unintelligible) That's why you beg to differ me, you ain't got no style Plus you lack delivery, not to brag I don't need to boast Look, my face is pale, but you look like you seen a ghost (unintelligible) You couldn't slip up in the zone, if I put banana peels Around this fucking microphone So get a bulldozer, start from bottom to top And tear this building down 'cause that's the only way you wrecking shop</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996 Underground Freestyle</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1997 Freestyle Live at Wetlands, NYC</th>\n",
              "      <td>[Verse 1] Everybody, duck down, all you hear i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997 Rap Olympics</th>\n",
              "      <td>[RAP BATTLE 1] I'ma tell you this for your own...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>[Intro] Hi kids, do you like Kim's bullshit? (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999 Tim Westwood Freestyle</th>\n",
              "      <td>[Verse 1: Eminem] Tim Westwood, Marley Marl an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004 Tim Westwood Freestyle</th>\n",
              "      <td>[Verse 1: Stat Quo] I boss how I live Fuck 'em...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Any rapper saying those kind of rhymes In this day and age in this period of time Tryna battle Eminem is worse than David Starr tryna battle Proof, Eye-Ku, BFlat and Bizarre (unintelligible) That's why you beg to differ me, you ain't got no style Plus you lack delivery, not to brag I don't need to boast Look, my face is pale, but you look like you seen a ghost (unintelligible) You couldn't slip up in the zone, if I put banana peels Around this fucking microphone So get a bulldozer, start from bottom to top And tear this building down 'cause that's the only way you wrecking shop\n",
              "1996 Underground Freestyle                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
              "1997 Freestyle Live at Wetlands, NYC  [Verse 1] Everybody, duck down, all you hear i...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "1997 Rap Olympics                     [RAP BATTLE 1] I'ma tell you this for your own...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "1999                                  [Intro] Hi kids, do you like Kim's bullshit? (...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "1999 Tim Westwood Freestyle           [Verse 1: Eminem] Tim Westwood, Marley Marl an...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "2004 Tim Westwood Freestyle           [Verse 1: Stat Quo] I boss how I live Fuck 'em...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFzYSuSJJN57",
        "colab_type": "code",
        "outputId": "e1921abc-a8ed-4f62-8473-7d2dc5492e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = open('/content/drive/My Drive/lyrics_eminem.txt', 'r')\n",
        "\n",
        "with open('/content/drive/My Drive/lyrics_eminem.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "type(text) # 1 huge string"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb2a4woUJK5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create function to clean and tokenize text\n",
        "def clean_doc(doc):\n",
        "\t# replace '--' with a space ' '\n",
        "\tdoc = doc.replace('--', ' ')\n",
        "\t# split into tokens by white space\n",
        "\ttokens = doc.split()\n",
        "\t# remove punctuation from each token\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# remove remaining tokens that are not alphabetic\n",
        "\ttokens = [word for word in tokens if word.isalpha()]\n",
        "\t# make lower case\n",
        "\ttokens = [word.lower() for word in tokens]\n",
        "\treturn tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh1BvWFL-dpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create function to save tokens to file, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "\tdata = '\\n'.join(lines)\n",
        "\tfile = open(filename, 'w')\n",
        "\tfile.write(data)\n",
        "\tfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1rfnXfGNY-G",
        "colab_type": "code",
        "outputId": "482d49c7-3650-4211-b5c0-96a5101c9e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# clean my text of lyrics\n",
        "tokens_list = clean_doc(text)\n",
        "print(tokens_list[:200])\n",
        "print('Total Tokens: %d' % len(tokens_list))\n",
        "print('Unique Tokens: %d' % len(set(tokens_list)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['look', 'i', 'was', 'gonna', 'go', 'easy', 'on', 'you', 'not', 'to', 'hurt', 'your', 'feelings', 'but', 'im', 'only', 'going', 'to', 'get', 'this', 'one', 'chance', 'somethings', 'wrong', 'i', 'can', 'feel', 'it', 'just', 'a', 'feeling', 'ive', 'got', 'like', 'somethings', 'about', 'to', 'happen', 'but', 'i', 'dont', 'know', 'what', 'if', 'that', 'means', 'what', 'i', 'think', 'it', 'means', 'were', 'in', 'trouble', 'big', 'trouble', 'and', 'if', 'he', 'is', 'as', 'bananas', 'as', 'you', 'say', 'im', 'not', 'taking', 'any', 'chances', 'you', 'are', 'just', 'what', 'the', 'doc', 'ordered', 'im', 'beginnin', 'to', 'feel', 'like', 'a', 'rap', 'god', 'rap', 'god', 'all', 'my', 'people', 'from', 'the', 'front', 'to', 'the', 'back', 'nod', 'back', 'nod', 'now', 'who', 'thinks', 'their', 'arms', 'are', 'long', 'enough', 'to', 'slap', 'box', 'slap', 'box', 'they', 'said', 'i', 'rap', 'like', 'a', 'robot', 'so', 'call', 'me', 'rapbot', 'but', 'for', 'me', 'to', 'rap', 'like', 'a', 'computer', 'it', 'must', 'be', 'in', 'my', 'genes', 'i', 'got', 'a', 'laptop', 'in', 'my', 'back', 'pocket', 'my', 'penll', 'go', 'off', 'when', 'i', 'halfcock', 'it', 'got', 'a', 'fat', 'knot', 'from', 'that', 'rap', 'profit', 'made', 'a', 'livin', 'and', 'a', 'killin', 'off', 'it', 'ever', 'since', 'bill', 'clinton', 'was', 'still', 'in', 'office', 'with', 'monica', 'lewinsky', 'feelin', 'on', 'his', 'nutsack', 'im', 'an', 'mc', 'still', 'as', 'honest', 'but', 'as', 'rude', 'and', 'as', 'indecent', 'as', 'all', 'hell', 'syllables']\n",
            "Total Tokens: 224109\n",
            "Unique Tokens: 15441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sOGOJLgJRlo",
        "colab_type": "code",
        "outputId": "606bb888-eb58-42f5-8c55-9da37d85bd57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Organizing tokens into sequences\n",
        "seq_length = 50 + 1\n",
        "sequences = list()\n",
        "for i in range(seq_length, len(tokens_list)):\n",
        "\t# select sequence of tokens\n",
        "\tseq = tokens_list[i-seq_length:i]\n",
        "\t# convert into a line\n",
        "\tline = ' '.join(seq)\n",
        "\t# store\n",
        "\tsequences.append(line)\n",
        "print('Total Sequences: %d' % len(sequences))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 224058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuxlxjaS9_Iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save sequences to file\n",
        "out_filename = 'final_eminem_lyrics.txt'\n",
        "save_doc(sequences, out_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ClEHHy2SgAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filepath):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filepath, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load\n",
        "in_filename = 'final_eminem_lyrics.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKRP5PxCS9A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Keras tokenizer to tokenizer and sequence data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "len(tokenizer.word_index)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIlSqMueTRgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# separate into input and output\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPhspEHtTZw3",
        "colab_type": "code",
        "outputId": "4e72f0f5-0218-46d9-fca5-0c2733e237a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# Designing LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 300, input_length=seq_length)) # 300 is dimension size\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 50, 300)           4632600   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50, 100)           160400    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15442)             1559642   \n",
            "=================================================================\n",
            "Total params: 6,443,142\n",
            "Trainable params: 6,443,142\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AMNLOxvHa-F",
        "colab_type": "code",
        "outputId": "e30ff227-d9ed-44ba-9070-066e7b4ffb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udnNPE71B6_h",
        "colab_type": "text"
      },
      "source": [
        "Finally... FIT THIS MODEL!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7TYpyKFB547",
        "colab_type": "code",
        "outputId": "9ac1013f-d5bc-406f-abdc-9cf53a5be07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# Fit model\n",
        "model.fit(X, y, batch_size=128, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "210176/224058 [===========================>..] - ETA: 34s - loss: 6.7082 - acc: 0.0380"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeAf0ecvIgeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "a242a0be-e19a-491c-be66-c089625f1934"
      },
      "source": [
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-49cfe079109a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# save the tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizer.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7EuKekiboTN",
        "colab_type": "text"
      },
      "source": [
        "Re-Loading Data and using Trained Model to Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHtL3Qx3ck5z",
        "colab_type": "code",
        "outputId": "74bb3bfe-dcee-454b-ea03-08aa0799f948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)\n",
        "\n",
        "# load cleaned text sequences\n",
        "in_filename = 'final_eminem_lyrics.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "seq_length = len(lines[0].split()) - 1\n",
        "\n",
        "# load the model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# load the tokenizer\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
        "\n",
        "# select a seed text\n",
        "seed_text = lines[randint(0,len(lines))]\n",
        "print(seed_text + '\\n')\n",
        "\n",
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
        "print(generated)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-13ab615772ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# load cleaned text sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0min_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'final_eminem_lyrics.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-13ab615772ef>\u001b[0m in \u001b[0;36mload_doc\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;31m# open the file as read only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m# read all text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final_eminem_lyrics.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDMuxunMihNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}